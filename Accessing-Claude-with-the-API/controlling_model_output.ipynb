{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67eabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "MODEL=\"claude-3-haiku-20240307\"\n",
    "TEMPERATURE=0.7\n",
    "SYSTEM_PROMT=\"You are a assistant that answers questions in one sentence.\"\n",
    "\n",
    "try:\n",
    "    client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Anthropic client: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2590cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "def add_user_message(messages, text):\n",
    "    messages.append({\"role\": \"user\", \"content\": text})\n",
    "    \n",
    "def add_assistant_message(messages, text):\n",
    "    messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "\n",
    "def get_response(messages, stop_sequences=[]):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL,\n",
    "        max_tokens=1000,\n",
    "        temperature=TEMPERATURE,\n",
    "        system=SYSTEM_PROMT,\n",
    "        messages=messages,\n",
    "        stop_sequences=stop_sequences\n",
    "    )\n",
    "\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7e550",
   "metadata": {},
   "source": [
    "# Prefilled Assistant Messages\n",
    "\n",
    "Message prefilling lets you provide the beginning of Claude's response, which it will then continue from that starting point. This technique is incredibly useful for steering Claude in a specific direction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9868ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_user_message(messages, \"Is tea better or coffee?\")\n",
    "add_assistant_message(messages, \"coffee is better than tea because\")\n",
    "res = get_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efbf552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " it has a stronger and more robust flavor.\n"
     ]
    }
   ],
   "source": [
    "print(res) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0195a",
   "metadata": {},
   "source": [
    "# Stop Sequences\n",
    "\n",
    "Stop sequences force Claude to end its response immediately when it generates a specific string of characters. This is perfect for controlling the length or endpoint of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "add_user_message(messages, \"Count from 1 to 10\")\n",
    "res = get_response(messages, stop_sequences=[\", 5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30683a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4\n"
     ]
    }
   ],
   "source": [
    "print(res)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe4447",
   "metadata": {},
   "source": [
    "# structured data\n",
    "\n",
    "When you need Claude to generate structured data like JSON, Python code, or bulleted lists, you'll often run into a common problem: Claude wants to be helpful and add explanatory text around your content. While this is usually great, sometimes you need just the raw data with nothing else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ac823",
   "metadata": {},
   "source": [
    "## example-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389e8852",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "add_user_message(messages, \"Generate a very short event bridge rule as json\")\n",
    "add_assistant_message(messages, \"```json\")\n",
    "res = get_response(messages, stop_sequences=[\"```\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf73878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"description\": \"Example Event Bridge Rule\",\n",
      "  \"eventBusName\": \"default\",\n",
      "  \"eventPattern\": {\n",
      "    \"source\": [\"aws.ec2\"],\n",
      "    \"detail-type\": [\"EC2 Instance State-change Notification\"],\n",
      "    \"detail\": {\n",
      "      \"state\": [\"running\", \"stopped\"]\n",
      "    }\n",
      "  },\n",
      "  \"state\": \"ENABLED\",\n",
      "  \"targets\": [\n",
      "    {\n",
      "      \"arn\": \"arn:aws:lambda:us-west-2:123456789012:function:my-lambda-function\",\n",
      "      \"id\": \"my-lambda-function\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e15b148",
   "metadata": {},
   "source": [
    "## example-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e527657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 ls\n",
      "aws ec2 describe-instances\n",
      "aws lambda invoke --function-name my-function output.txt\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "\n",
    "add_user_message(messages, \"generate 3 different sample aws cli commands. each should be very short.\")\n",
    "add_assistant_message(messages, \"here are three sample AWS CLI commands without any comments and numbering ('1.', '2.', etc):\")\n",
    "res = get_response(messages)\n",
    "print(res.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29c867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HelloWorld-Claude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
