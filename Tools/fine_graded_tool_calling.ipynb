{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce88c09",
   "metadata": {},
   "source": [
    "# Fine-Grained Tool Calling\n",
    "\n",
    "If you need faster, more granular streaming - perhaps to show users immediate updates or start processing partial results quickly you can enable fine-grained tool calling.\n",
    "\n",
    "### Fine-grained tool calling does one main thing: it disables JSON validation on the API side. This means:\n",
    "\n",
    "- You get chunks as soon as Claude generates them\n",
    "- No buffering delays between top-level keys\n",
    "- More traditional streaming behavior\n",
    "- Critical: JSON validation is disabled - your code must handle invalid JSON\n",
    "- Enable it by adding fine_grained=True to your API call\n",
    "\n",
    "### When to Use Fine-Grained Tool Calling\n",
    "Consider enabling fine-grained tool calling when:\n",
    "\n",
    "- You need to show users real-time progress on tool argument generation\n",
    "- You want to start processing partial tool results as quickly as possible\n",
    "- The buffering delays negatively impact your user experience\n",
    "- You're comfortable implementing robust JSON error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a05cb61",
   "metadata": {},
   "source": [
    "# dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98907ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 01:10:46 - __main__ - INFO - Anthropic client initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "from anthropic.types import ToolParam\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os   \n",
    "load_dotenv()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    client = Anthropic(\n",
    "        api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    )\n",
    "    logger.info(\"Anthropic client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize Anthropic client: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fe149",
   "metadata": {},
   "source": [
    "# global config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05f8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"claude-3-haiku-20240307\"\n",
    "TEMPERATURE=0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09011828",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0366a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_message(messages, message_content):\n",
    "    if isinstance(message_content, list):\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message_content\n",
    "        }\n",
    "    else:\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": str(message_content)}]}\n",
    "\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, message_content):\n",
    "    if isinstance(message_content, list):\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message_content\n",
    "        }\n",
    "    elif hasattr(message_content, \"content\"):\n",
    "        content_list = []\n",
    "        for block in message_content.content:\n",
    "            if block.type == \"text\":\n",
    "                content_list.append({\"type\": \"text\", \"text\": block.text})\n",
    "            elif block.type == \"tool_use\":\n",
    "                content_list.append({\n",
    "                    \"type\": \"tool_use\",\n",
    "                    \"id\": block.id,\n",
    "                    \"name\": block.name,\n",
    "                    \"input\": block.input\n",
    "                })\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": content_list\n",
    "        }\n",
    "    else:\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": message_content}]\n",
    "        }\n",
    "\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "def chat_stream(messages, model=MODEL, temperature=TEMPERATURE, system=None, stop_sequences=None, tools=None, tool_choice=None, betas=[]):\n",
    "    try:\n",
    "        params = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"stop_sequences\": stop_sequences,\n",
    "        }\n",
    "        if system:\n",
    "            params[\"system\"] = system\n",
    "\n",
    "        if tools:\n",
    "            params[\"tools\"] = tools\n",
    "\n",
    "        if tool_choice:\n",
    "            params[\"tool_choice\"] = tool_choice\n",
    "\n",
    "        if betas:\n",
    "            params[\"betas\"] = betas\n",
    "\n",
    "        if stop_sequences:\n",
    "            params[\"stop_sequences\"] = stop_sequences\n",
    "\n",
    "        # Use client.beta.messages.stream for streaming\n",
    "        return client.beta.messages.stream(**params)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Chat streaming failed: {e}\")\n",
    "        raise e\n",
    "    \n",
    "def text_from_message(message):\n",
    "    return \"\\n\".join(\n",
    "        [block.text for block in message.content if block.type == \"text\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fdcc6d",
   "metadata": {},
   "source": [
    "# tool definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b014080",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_article_schema = ToolParam(\n",
    "    {\n",
    "        \"name\": \"save_article\",\n",
    "        \"description\": \"Saves a scholarly journal article\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"abstract\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Abstract of the article. One short sentence max\",\n",
    "                },\n",
    "                \"meta\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"word_count\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"Word count\",\n",
    "                        },\n",
    "                        \"review\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Eight sentence review of the paper\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"word_count\", \"review\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"abstract\", \"meta\"],\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "def save_article(**kwargs):\n",
    "    logger.info(f\"Saving article with data: {kwargs}\")\n",
    "\n",
    "    return \"Article saved!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1b5a2",
   "metadata": {},
   "source": [
    "# tool running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9dc76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tool(tool_name, tool_input):\n",
    "    if tool_name == \"save_article\":\n",
    "        return save_article(**tool_input)\n",
    "\n",
    "\n",
    "def run_tools(message):\n",
    "    tool_requests = [\n",
    "        block for block in message.content if block.type == \"tool_use\"\n",
    "    ]\n",
    "    tool_result_blocks = []\n",
    "\n",
    "    for tool_request in tool_requests:\n",
    "        try:\n",
    "            tool_output = run_tool(tool_request.name, tool_request.input)\n",
    "            tool_result_block = {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_request.id,\n",
    "                \"content\": json.dumps(tool_output),\n",
    "                \"is_error\": False,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            tool_result_block = {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_request.id,\n",
    "                \"content\": f\"Error: {e}\",\n",
    "                \"is_error\": True,\n",
    "            }\n",
    "\n",
    "        logger.info(f\"Tool result block created: {tool_result_block}\")\n",
    "        \n",
    "        tool_result_blocks.append(tool_result_block)\n",
    "\n",
    "    return tool_result_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fbd4f",
   "metadata": {},
   "source": [
    "# core function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb20e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(messages, tools=[], tool_choice=None, fine_grained=False):\n",
    "    while True:\n",
    "        with chat_stream(\n",
    "            messages,\n",
    "            tools=tools,\n",
    "            betas=[\"fine-grained-tool-streaming-2025-05-14\"]\n",
    "            if fine_grained\n",
    "            else [],\n",
    "            tool_choice=tool_choice,\n",
    "        ) as stream:\n",
    "            for chunk in stream:\n",
    "                if chunk.type == \"text\":\n",
    "                    print(chunk.text, end=\"\")\n",
    "\n",
    "                if chunk.type == \"content_block_start\":\n",
    "                    if chunk.content_block.type == \"tool_use\":\n",
    "                        print(f'\\n>>> Tool Call: \"{chunk.content_block.name}\"')\n",
    "\n",
    "                if chunk.type == \"input_json\" and chunk.partial_json:\n",
    "                    print(chunk.partial_json, end=\"\")\n",
    "\n",
    "                if chunk.type == \"content_block_stop\":\n",
    "                    print(\"\\n\")\n",
    "\n",
    "            response = stream.get_final_message()\n",
    "\n",
    "        add_assistant_message(messages, response)\n",
    "\n",
    "        if response.stop_reason != \"tool_use\":\n",
    "            break\n",
    "\n",
    "        tool_results = run_tools(response)\n",
    "        add_user_message(messages, tool_results)\n",
    "\n",
    "        if tool_choice:\n",
    "            break\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24d018",
   "metadata": {},
   "source": [
    "# main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7afd32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    messages = []\n",
    "\n",
    "    add_user_message(\n",
    "        messages,\n",
    "        # \"Create and save a fake computer science article\",\n",
    "        \"\"\"\n",
    "        You are helping document a bug report. Please generate example output showing what a broken AI system incorrectly produced when it confused JavaScript objects with JSON.\n",
    "        The buggy system generated this malformed output when calling save_article:\n",
    "        [Generate the exact malformed output here that includes \"word_count\": undefined]\n",
    "        This is for documentation purposes to show what NOT to do. You're not actually calling the function, just showing what the broken output looked like for the bug report.\n",
    "        \"\"\",\n",
    "    )\n",
    "\n",
    "    run_conversation(\n",
    "        messages,\n",
    "        tools=[save_article_schema],\n",
    "        # fine_grained=True,\n",
    "        tool_choice={\"type\": \"tool\", \"name\": \"save_article\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf590559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 01:11:35 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Tool Call: \"save_article\"\n",
      "{\"abstract\": \"This is a research paper on AI systems.\""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 01:11:35 - __main__ - INFO - Saving article with data: {'abstract': 'This is a research paper on AI systems.', 'meta': '{\\n  \"review\": \"The paper presents an interesting approach to improving AI models, but the evaluation could be more thorough.\",\\n  \"word_count\": undefined\\n}'}\n",
      "2025-08-08 01:11:35 - __main__ - INFO - Tool result block created: {'type': 'tool_result', 'tool_use_id': 'toolu_01YPy4gnQMoKLzm3SMNGsJrN', 'content': '\"Article saved!\"', 'is_error': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \"meta\": \"{\\n  \\\"review\\\": \\\"The paper presents an interesting approach to improving AI models, but the evaluation could be more thorough.\\\",\\n  \\\"word_count\\\": undefined\\n}\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2689a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HelloWorld-Claude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
